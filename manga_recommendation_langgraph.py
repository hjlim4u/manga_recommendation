from typing import Dict, List, TypedDict, Optional, Literal
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
from langchain_tavily import TavilySearch
import asyncio
import json
import re
from dotenv import load_dotenv
import nest_asyncio
from domain import Gender, AgeGroup, AgeRating
from vector_store import QdrantMangaStore
from data_source import MangaDataSource, CSVMangaDataSource, MockDatabaseMangaDataSource, DatabaseMangaDataSource
from prompt_templates import PromptTemplates

nest_asyncio.apply()
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ===== State ì •ì˜ =====
class RecommendationState(TypedDict):
    """ì¶”ì²œ ì‹œìŠ¤í…œì˜ ìƒíƒœ"""
    # ì‚¬ìš©ì ì…ë ¥
    user_gender: Literal["ë‚¨", "ì—¬", "ë„˜ì–´ê°€ê¸°"]
    user_age_group: Literal["12~15", "15~18", "18~30", "30~40", "40~50", "50~"]
    user_genres: List[str]
    user_favorite_manga: str
    
    # ì²˜ë¦¬ëœ í”„ë¡œí•„
    processed_profile: Dict
    
    # ğŸ”§ ì¢‹ì•„í•˜ëŠ” ë§Œí™” Documentë“¤ (íš¨ìœ¨ì  ì €ì¥)
    favorite_manga_docs: List[Document]
    
    # ê²€ìƒ‰ ê²°ê³¼
    search_results: List[Document]
    search_attempt: int

    # ì¶”ì²œ ê²°ê³¼
    recommendations: List[Dict]
    recommendation_quality: float
    
    # ê²€ì¦ ê´€ë ¨
    needs_refinement: bool



# ===== ë©”ì¸ ë…¸ë“œ í´ë˜ìŠ¤ =====
class MangaRecommendationNodes:
    def __init__(self, data_source: MangaDataSource):
        # ë°ì´í„° ì†ŒìŠ¤ ì €ì¥
        self.data_source = data_source
        
        # ë²¡í„° ìŠ¤í† ì–´
        self.vector_store = QdrantMangaStore()
        
        # LLM
        self.llm = ChatOpenAI(temperature=0.3, model="gpt-4o-mini")
        
        # ì›¹ ê²€ìƒ‰
        self.web_search_tool = TavilySearch(max_results=3)
        
        # ë°ì´í„° ì´ˆê¸°í™”
        self._initialize_data()
    
    def _initialize_data(self):
        """ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ ë° ë²¡í„° DB ì¸ë±ì‹±"""
        try:
            # ë°ì´í„° ì†ŒìŠ¤ë¥¼ í†µí•´ ë¡œë“œ ë° ì¸ë±ì‹±
            self.vector_store.load_and_index_from_source(self.data_source)
            
        except Exception as e:
            raise

    
    def process_user_profile(self, state: RecommendationState) -> RecommendationState:
        """ì‚¬ìš©ì ì…ë ¥ì„ í”„ë¡œí•„ë¡œ ë³€í™˜ + ì¢‹ì•„í•˜ëŠ” ë§Œí™” ê²€ìƒ‰"""
        gender = Gender.from_option(state['user_gender'])
        age_group = AgeGroup.from_option(state['user_age_group'])
        
        profile = {
            'gender': gender.value,
            'age_group': age_group.value,
            'preferred_genres': state['user_genres'],
            'favorite_manga': self._parse_favorite_manga(state['user_favorite_manga']),
            'max_age_rating': age_group.min_age
        }
        
        # ğŸ”§ ë²¡í„° DBë¥¼ í™œìš©í•œ ì¢‹ì•„í•˜ëŠ” ë§Œí™” ê²€ìƒ‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        favorite_manga_docs = []
        not_found_titles = []
        
        for title in profile['favorite_manga']:
            found_doc = self.vector_store.find_manga_by_title(title)
            if found_doc:
                favorite_manga_docs.append(found_doc)
            else:
                not_found_titles.append(title)
        
        state['processed_profile'] = profile
        state['favorite_manga_docs'] = favorite_manga_docs  # ğŸ”§ ìƒíƒœì— ì €ì¥
        state['search_attempt'] = 0
        
        return state
    
    
    def _parse_favorite_manga(self, manga_text: str) -> List[str]:
        """ì¢‹ì•„í•˜ëŠ” ë§Œí™” í…ìŠ¤íŠ¸ íŒŒì‹±"""
        import re
        manga_list = re.split(r'[,/\n]|ê³¼\s|ì™€\s|ë‘\s', manga_text)
        return [m.strip() for m in manga_list if m.strip() and len(m.strip()) > 1]
    
    async def search_similar_manga(self, state: RecommendationState) -> RecommendationState:
        """ë²¡í„° ê²€ìƒ‰ (ìµœëŒ€ 2íšŒ ì‹œë„)"""
        profile = state['processed_profile']
        favorite_manga_docs = state['favorite_manga_docs']  # ğŸ”§ ìƒíƒœì—ì„œ ê°€ì ¸ì˜¤ê¸°
        attempt = state.get('search_attempt', 0)
        
        if attempt == 0:
            # ì „ëµ 1: ì¤‘ì‹¬ì  ì„ë² ë”©
            results = self.vector_store.search_similar_manga_by_centroid(
                favorite_manga_docs=favorite_manga_docs,
                preferred_genres=profile['preferred_genres'],
                max_age_rating=profile['max_age_rating'],
                limit=30
            )
        else:
            # ì „ëµ 2: ê°œë³„ ê²€ìƒ‰ í›„ ë³‘í•©
            results = self.vector_store.search_similar_manga_by_individual(
                favorite_manga_docs=favorite_manga_docs,
                preferred_genres=profile['preferred_genres'],
                max_age_rating=profile['max_age_rating'],
                limit_per_manga=15
            )
        
        state['search_results'] = results
        state['search_attempt'] = attempt + 1
        
        return state
    
    async def enrich_with_web_search(self, state: RecommendationState) -> RecommendationState:
        """ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë°ì´í„° ë³´ê°•"""
        candidates = state['search_results'][:8]
        profile = state['processed_profile']
        
        # 1. ì„ í˜¸ ë§Œí™” ì •ë³´ ìˆ˜ì§‘
        favorite_manga_info = {}
        
        # 2. í›„ë³´ ë§Œí™” ê²€ìƒ‰
        async def search_manga_info(doc):
            try:
                query = PromptTemplates.generate_web_search_query(doc.metadata['title'])
                result = await asyncio.to_thread(
                    self.web_search_tool.invoke,
                    {"query": query}
                )
                
                if result and 'results' in result:
                    summaries = []
                    for r in result['results'][:2]:
                        if 'content' in r:
                            summaries.append(r['content'][:200])
                    doc.metadata['web_info'] = ' '.join(summaries)
                else:
                    doc.metadata['web_info'] = ''
            except Exception as e:
                doc.metadata['web_info'] = ''
            
            return doc
        # ì„ í˜¸ ë§Œí™” ê²€ìƒ‰ (ìµœëŒ€ 2ê°œ)
        favorite_tasks = [search_manga_info(doc) for doc in state['favorite_manga_docs'][:2]]
        favorite_manga_info = await asyncio.gather(*favorite_tasks)
        
        candidate_tasks = [search_manga_info(doc) for doc in candidates]
        enriched_candidates = await asyncio.gather(*candidate_tasks)
        
        state['favorite_manga_docs'] = favorite_manga_info
        state['search_results'] = enriched_candidates
        
        return state
    
    def generate_recommendations(self, state: RecommendationState) -> RecommendationState:
        """LLM ê¸°ë°˜ ì¶”ì²œ ìƒì„± - ì¸ë±ìŠ¤ ê¸°ë°˜"""
        candidates = state['search_results']
        profile = state['processed_profile']
        favorite_docs = state.get('favorite_manga_docs', [])
        
        if not candidates:
            state['recommendations'] = []
            return state
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±
        prompt = PromptTemplates.generate_recommendation_prompt(
            favorite_docs=favorite_docs,
            profile=profile,
            candidates=candidates
        )
        
        response = self.llm.invoke(prompt)
        
        try:
            # JSON íŒŒì‹±
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                llm_recommendations = result.get('recommendations', [])
            else:
                raise ValueError("JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ìƒì„±
            recommendations = self._create_recommendations_from_indices(
                llm_recommendations, candidates
            )
            
        except Exception as e:
            # ë¹ˆ ë°°ì—´ë¡œ ì´ˆê¸°í™” - validate_resultsì—ì„œ ì¬ì‹œë„ ì²˜ë¦¬
            recommendations = []
        
        # ğŸ” ìµœì¢… ì¶”ì²œì— ì¢‹ì•„í•˜ëŠ” ë§Œí™”ê°€ í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
        favorite_manga_titles = [doc.metadata.get('title') for doc in state.get('favorite_manga_docs', []) if hasattr(doc, 'metadata')]
        favorite_manga_ids = [doc.metadata.get('manga_id') for doc in state.get('favorite_manga_docs', []) if hasattr(doc, 'metadata')]
        
        state['recommendations'] = recommendations
        state['search_results'] = candidates  # candidatesë„ stateì— ì €ì¥ (ë‚˜ì¤‘ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´)
        
        return state
    
    def _create_recommendations_from_indices(self, llm_recommendations: List[Dict], candidates: List[Document]) -> List[Dict]:
        """ì¸ë±ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ìƒì„± - ë§¤ìš° ê°„ë‹¨! (ì¸ë±ìŠ¤ + ì´ìœ ë§Œ ì €ì¥)"""
        recommendations = []
        used_indices = set()
        
        for llm_rec in llm_recommendations:
            index = llm_rec.get('index', 0)
            reason = llm_rec.get('reason', 'ì¶”ì²œ')
            
            # ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
            if 1 <= index <= len(candidates) and index not in used_indices:
                used_indices.add(index)
                
                # ì¸ë±ìŠ¤ì™€ ì´ìœ ë§Œ ì €ì¥ (ë©”íƒ€ë°ì´í„° ì¤‘ë³µ ì œê±°)
                rec = {
                    'index': index,
                    'recommendation_reason': reason
                }
                recommendations.append(rec)

        
        # 3ê°œ ë¯¸ë§Œì¸ ê²½ìš° ìƒìœ„ í›„ë³´ë¡œ ì±„ìš°ê¸°
        while len(recommendations) < 3:
            for i in range(1, len(candidates) + 1):
                if i not in used_indices:
                    rec = {
                        'index': i,
                        'recommendation_reason': "ë†’ì€ ìœ ì‚¬ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì¶”ì²œ"
                    }
                    recommendations.append(rec)
                    used_indices.add(i)
                    
                    break
            else:
                break
        
        return recommendations[:3]
    
    def validate_results(self, state: RecommendationState) -> RecommendationState:
        """JSON ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼ ê²€ì¦ - 3ê°œ ì¶”ì²œ ë²„ì „ (ì¸ë±ìŠ¤ ë°©ì‹)"""
        recommendations = state['recommendations']
        candidates = state['search_results']
        profile = state['processed_profile']
        
        # ğŸ”‘ í•µì‹¬: ìµœëŒ€ ì‹œë„ íšŸìˆ˜ë¥¼ ë¨¼ì € ì²´í¬í•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
        if state.get('search_attempt', 0) >= 2:
            state['needs_refinement'] = False
            state['recommendation_quality'] = 0.8  # ê¸°ë³¸ ì ìˆ˜
            return state
        
        if len(recommendations) < 3:
            state['recommendation_quality'] = 0.6  # ë‚®ì€ ì ìˆ˜
            state['needs_refinement'] = True  
            return state
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±
        validation_prompt = PromptTemplates.generate_validation_prompt(
            profile=profile,
            recommendations=recommendations,
            candidates=candidates
        )
        
        try:
            response = self.llm.invoke(validation_prompt)
            
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                
                state['recommendation_quality'] = result.get('score', 0) / 100.0
                state['needs_refinement'] = not result.get('pass', False)
            else:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í†µê³¼
                state['recommendation_quality'] = 0.8
                state['needs_refinement'] = False
                
        except Exception as e:
            state['recommendation_quality'] = 0.8
            state['needs_refinement'] = False
        
        return state

# ===== ê·¸ë˜í”„ êµ¬ì„± =====
def create_recommendation_graph(data_source: MangaDataSource) -> StateGraph:
    """ì¶”ì²œ ì‹œìŠ¤í…œ ê·¸ë˜í”„ ìƒì„± - sequential ë©”ì†Œë“œ í™œìš©"""
    
    nodes = MangaRecommendationNodes(data_source)
    
    workflow = StateGraph(RecommendationState)
    
    # sequential ë©”ì†Œë“œë¡œ ì—°ì† ë…¸ë“œë“¤ì„ í•œë²ˆì— ì—°ê²°
    # ë°ì´í„° ì²˜ë¦¬ ë° ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸
    workflow.add_sequence([
        nodes.process_user_profile,     # ì‚¬ìš©ì í”„ë¡œí•„ ì²˜ë¦¬
        nodes.search_similar_manga,     # ë²¡í„° ê²€ìƒ‰
        nodes.enrich_with_web_search    # ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë°ì´í„° ë³´ê°•
    ])
    
    # ì¶”ì²œ ìƒì„± ë° ê²€ì¦ íŒŒì´í”„ë¼ì¸
    workflow.add_sequence([
        nodes.generate_recommendations, # ì¶”ì²œ ìƒì„±
        nodes.validate_results         # ê²°ê³¼ ê²€ì¦
    ])
    
    # ì—£ì§€ ì •ì˜ - ì‹œí€€ìŠ¤ ê°„ ì—°ê²°
    workflow.set_entry_point("process_user_profile")
    workflow.add_edge("enrich_with_web_search", "generate_recommendations")
    
    # ì¡°ê±´ë¶€ ì—£ì§€ - ì¬ì‹œë„ ë¡œì§
    def should_retry_or_end(state: RecommendationState) -> str:
        if state.get('needs_refinement', False):
            return "retry_search"
        return "end"
    
    workflow.add_conditional_edges(
        "validate_results",
        should_retry_or_end,
        {
            "retry_search": "search_similar_manga",  # ì¬ì‹œë„ ì‹œ ë²¡í„° ê²€ìƒ‰ë¶€í„°
            "end": END
        }
    )
    
    return workflow.compile()

# ===== ë©”ì¸ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©) =====
if __name__ == "__main__":
    """
    í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©. ì‹¤ì œ ì‹¤í–‰ì€ main.pyë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    """
    print("ì´ íŒŒì¼ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª¨ë“ˆì…ë‹ˆë‹¤. main.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.") 